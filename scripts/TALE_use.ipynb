{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "voq_EIyaOPzX",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure TensorFlow is below 2.16! Otherwise the model won't be able to load.\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkkgAZHvWhh8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GPU info:\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mHxe2YXWhh9"
   },
   "outputs": [],
   "source": [
    "# Assign GPU to use:\n",
    "GPU_id = '6'\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = GPU_id\n",
    "\n",
    "# check:\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "98NU5NCGWhh9"
   },
   "outputs": [],
   "source": [
    "# check:\n",
    "sess = tf.compat.v1.Session()\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(gpu_devices) > 0:\n",
    "    print(\"GPU working\")\n",
    "else:\n",
    "    print(\"GPU not working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yjElLEtyWhh-"
   },
   "outputs": [],
   "source": [
    "# check:\n",
    "for device in gpu_devices:\n",
    "    print(\"device name:\", device.name)\n",
    "    print(\"device type:\", device.device_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xkr_7oyPWhh-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "L5_8mer_df = pd.read_table('/rd4/users/liangn/L5_2-8mer.tsv')\n",
    "L5_8mer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RAQNScryWhh_"
   },
   "outputs": [],
   "source": [
    "# 8-mer mutagenesis:\n",
    "\n",
    "# Function to generate a list of all possible mutations for a seq:\n",
    "def all_possible_mutations(dna_seq):\n",
    "    mutated_seqs = []\n",
    "    for i in range(len(dna_seq)):\n",
    "        for nucleotide in [\"A\", \"T\", \"C\", \"G\"]:\n",
    "            if nucleotide != dna_seq[i]:\n",
    "                mutated_seq = dna_seq[:i] + nucleotide + dna_seq[i+1:]\n",
    "                mutated_seqs.append(mutated_seq)\n",
    "    #\n",
    "    return mutated_seqs\n",
    "\n",
    "\n",
    "# functions to get a df of the regulatory relevance of each nucleotide of 8-mer:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def kmer_saliency_df(kmer = 'GGTAAGTA', target = 'delta.log2expression'):\n",
    "    # generate all point mutations:\n",
    "    all_mutants = all_possible_mutations(kmer)\n",
    "    # add the original seq to the mutant list:\n",
    "    all_mutants.insert(0, kmer)\n",
    "    # create empty df:\n",
    "    kmer_values = pd.DataFrame(columns=['kmer', 'value'])\n",
    "    # find values by each k-mer:\n",
    "    for the_kmer in all_mutants:\n",
    "        match = L5_8mer_df.loc[L5_8mer_df['kmer'] == the_kmer, target]\n",
    "        new_row = pd.DataFrame({'kmer': [the_kmer], 'value': [match.values[0]]})\n",
    "        kmer_values = pd.concat([kmer_values, new_row], ignore_index=True)\n",
    "    # calculate delta:\n",
    "    values = kmer_values['value'].values\n",
    "    deltas = values[0] - values[1:]\n",
    "    # median deltas of each original nucleotide/position:\n",
    "    delta_medians = []\n",
    "    for i in range(3, len(deltas)+1, 3):\n",
    "        median = np.median(deltas[i-3:i])\n",
    "        delta_medians.append(median)\n",
    "    # form the final data.frame suitable for logomaker:\n",
    "    position_list = list(kmer)\n",
    "    final_df = pd.DataFrame(columns=['A', 'C', 'G', 'T'])\n",
    "    for i, letter in enumerate(position_list):\n",
    "        final_df.at[i, letter] = delta_medians[i]\n",
    "    final_df = final_df.fillna(0)\n",
    "    final_df = final_df.astype('float64')\n",
    "    # change row index to 1,2,3...:\n",
    "    final_df.index = range(1, len(final_df) + 1)\n",
    "    #\n",
    "    return final_df\n",
    "\n",
    "\n",
    "# function to plot nucleotide saliencies:\n",
    "import logomaker\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_saliency(df, negative=False,\n",
    "                  start=None, end=None, figsize=[8,2],\n",
    "                  xticks=False, yticks=False,\n",
    "                  spines=False, ylim=None):\n",
    "    # make Figure and Axes objects:\n",
    "    fig, ax = plt.subplots(1,1,figsize=figsize)\n",
    "    # limit x range, if defined:\n",
    "    if start is not None and end is not None:\n",
    "        df = df[start : end+1]\n",
    "    elif start is not None:\n",
    "        df = df[start : ]\n",
    "    elif end is not None:\n",
    "        df = df[ : end+1]\n",
    "    # flip saliencies if defined:\n",
    "    if negative == True:\n",
    "        df = -df\n",
    "    #\n",
    "    logo = logomaker.Logo(df, ax=ax)\n",
    "    #\n",
    "    if ylim is not None:\n",
    "        logo.ax.set_ylim(ylim)\n",
    "    #\n",
    "    if spines==False:\n",
    "        logo.style_spines(visible=False)\n",
    "    #\n",
    "    if xticks==False:\n",
    "        ax.set_xticks([])\n",
    "    #\n",
    "    if yticks==False:\n",
    "        ax.set_yticks([])\n",
    "    #\n",
    "    return logo.fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kum-RaV8Whh_"
   },
   "outputs": [],
   "source": [
    "# k-mer motif:\n",
    "kmer = 'AGGTAAGT'\n",
    "target = 'delta.log2expression' # delta.log2expression / delta.log2export\n",
    "\n",
    "the_kmer_saliency_df = kmer_saliency_df(kmer=kmer, target=target)\n",
    "the_kmer_saliency_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AyfKmLi3WhiA"
   },
   "outputs": [],
   "source": [
    "plot_saliency(df=the_kmer_saliency_df, negative=True, figsize=[3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1BIznd3tWhiA"
   },
   "outputs": [],
   "source": [
    "# k-mer context dependencies:\n",
    "\n",
    "\n",
    "# Define the model:\n",
    "model = '/rd4/users/liangn/L5-220528_em5-LSTM64x32x0.5-64x0.5-rep4.hdf5'\n",
    "model_x_length = 46\n",
    "optimal_x_length = 45\n",
    "\n",
    "\n",
    "# Function to convert a DNA sequence to vector:\n",
    "vocab = ['pad','N','A','T','C','G']\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "def vectorize_dna_seq(dna_seq):\n",
    "    vectorized_dna_seq = [char2idx[char] for char in dna_seq]\n",
    "    return vectorized_dna_seq\n",
    "\n",
    "\n",
    "# Function to convert a list of DNA into x array for ANN inputs:\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "def prepare_x(dna_list, x_lenth):\n",
    "    x = list(map(vectorize_dna_seq, dna_list))\n",
    "    x = pad_sequences(x, maxlen=x_lenth, padding='post')\n",
    "    #\n",
    "    return x\n",
    "\n",
    "\n",
    "# function to split a string into k-mers:\n",
    "def kmerize(string, k):\n",
    "    return [string[i:i+k] for i in range(len(string)-k+1)]\n",
    "\n",
    "\n",
    "# function to predict big seq with sliding windows:\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "def predict_big(big_seqs, k=optimal_x_length, model_x_length=model_x_length, model=model):\n",
    "    # form data.frame:\n",
    "    # if big_seqs only had one, convert to a list as well:\n",
    "    if isinstance(big_seqs, str):\n",
    "        big_seqs = [big_seqs]\n",
    "    seq_df = pd.DataFrame({'seq': big_seqs})\n",
    "    # split each seq into k-mers, mark indexes:\n",
    "    seq_df = seq_df['seq'].apply(lambda x: kmerize(x, k))\n",
    "    seq_df = seq_df.apply(pd.Series)\n",
    "    seq_df = seq_df.stack().reset_index(level=1, drop=True).to_frame('seq')\n",
    "    # prepare x for predictions:\n",
    "    x = seq_df['seq'].apply(vectorize_dna_seq)\n",
    "    x = pad_sequences(x, maxlen=model_x_length, padding='post')\n",
    "    # predict:\n",
    "    Model = load_model(model)\n",
    "    y_pred = Model.predict(x)\n",
    "    # take group means of the same indexes:\n",
    "    unique_index = np.unique(seq_df.index)\n",
    "    y_pred_mean = np.zeros((len(unique_index), y_pred.shape[1]))\n",
    "    for i in range(len(unique_index)):\n",
    "        y_pred_mean[i] = np.mean(y_pred[seq_df.index == unique_index[i]], axis=0)\n",
    "    #\n",
    "    return y_pred_mean\n",
    "\n",
    "\n",
    "# function to get a df of the regulatory relevance of each nucleotide of a seq:\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "def saliency_df(seq, optimal_x_length=optimal_x_length, model_x_length=model_x_length, model=model,\n",
    "                target='expression'):\n",
    "    # generate all point mutations:\n",
    "    all_mutants = all_possible_mutations(seq)\n",
    "    # add the original seq to the mutant list:\n",
    "    all_mutants.insert(0, seq)\n",
    "    # check seq length:\n",
    "    seq_len = len(seq)\n",
    "    # predict the mutants:\n",
    "    # use different prediction strategy by seq length:\n",
    "    if seq_len == optimal_x_length:\n",
    "        x = prepare_x(all_mutants, model_x_length)\n",
    "        Model = load_model(model)\n",
    "        y_pred = Model.predict(x)\n",
    "    else:\n",
    "        y_pred = predict_big(big_seqs=all_mutants, k=optimal_x_length, model_x_length=model_x_length,\n",
    "                             model=model)\n",
    "    # convert array to dataframe:\n",
    "    pred_df = pd.DataFrame(y_pred, columns = ['nuc','cyt'])\n",
    "    # calculate values:\n",
    "    pred_df['nuc'] = 2**pred_df['nuc']\n",
    "    pred_df['cyt'] = 2**pred_df['cyt']\n",
    "    pred_df['expression'] = pred_df['cyt']*(16/17) + pred_df['nuc']*(1/17)\n",
    "    pred_df['export'] = pred_df['cyt']/pred_df['nuc']\n",
    "    # calculate delta:\n",
    "    values = pred_df[target].values\n",
    "    deltas = values[0] - values[1:]\n",
    "    # median deltas of each original nucleotide/position:\n",
    "    delta_medians = []\n",
    "    for i in range(3, len(deltas)+1, 3):\n",
    "      median = np.median(deltas[i-3:i])\n",
    "      delta_medians.append(median)\n",
    "    # form the final data.frame suitable for logomaker:\n",
    "    seq_list = list(seq)\n",
    "    df = pd.DataFrame(columns=['A', 'C', 'G', 'T'])\n",
    "    for i, letter in enumerate(seq_list):\n",
    "      df.at[i, letter] = delta_medians[i]\n",
    "    df = df.fillna(0)\n",
    "    df = df.astype('float64')\n",
    "    # change row index to 1,2,3...:\n",
    "    df.index = range(1, len(df) + 1)\n",
    "    #\n",
    "    return df\n",
    "\n",
    "\n",
    "# Function that performs one evolutionary step on the context of a k-mer:\n",
    "def evolve_target_saliency_once(seq, left_i=19, right_i=26, target='expression',\n",
    "                                 negative=True, decreasing=False):\n",
    "    # generate all mutants:\n",
    "    all_mutants = all_possible_mutations(seq)\n",
    "    # remove mutations on the k-mer:\n",
    "    del all_mutants[(left_i-1)*3 : right_i*3]\n",
    "    # add the original seq to the mutant list:\n",
    "    all_mutants.insert(0, seq)\n",
    "    # calculate target saliency of each mutant:\n",
    "    mut_saliencies = pd.DataFrame(columns=['seq', 'saliency'])\n",
    "    for the_seq in all_mutants:\n",
    "        the_N45_saliency_df = saliency_df(the_seq, target=target)\n",
    "        the_targeted_saliency = the_N45_saliency_df.loc[left_i:right_i].sum().sum()\n",
    "        if negative == True:\n",
    "            the_targeted_saliency = -the_targeted_saliency\n",
    "        new_data = pd.DataFrame({'seq': [the_seq], 'saliency': [the_targeted_saliency]})\n",
    "        mut_saliencies = pd.concat([mut_saliencies, new_data], ignore_index=True)\n",
    "    # only report improved ones:\n",
    "    if decreasing==True:\n",
    "        mut_saliencies = mut_saliencies.loc[mut_saliencies['saliency']<mut_saliencies['saliency'][0]]\n",
    "    else:\n",
    "        mut_saliencies = mut_saliencies.loc[mut_saliencies['saliency']>mut_saliencies['saliency'][0]]\n",
    "    # sort df by target:\n",
    "    mut_saliencies = mut_saliencies.sort_values(by='saliency', ascending=decreasing)\n",
    "    #\n",
    "    return mut_saliencies\n",
    "\n",
    "\n",
    "# Function that evolves the context of a k-mer to the extreme:\n",
    "def extreme_target_saliency_evolve(seq, left_i=19, right_i=26, target='expression',\n",
    "                                   negative=True, decreasing=False):\n",
    "    # initiate the evolution:\n",
    "    df = evolve_target_saliency_once(seq=seq, left_i=left_i, right_i=right_i, target=target,\n",
    "                                     negative=negative, decreasing=decreasing)\n",
    "    # continue evolution if possible:\n",
    "    if len(df.index)>0:\n",
    "        new_seq = df.iloc[0]['seq']\n",
    "        new_df = df\n",
    "        while len(new_df.index)>0:\n",
    "            new_df = evolve_target_saliency_once(seq=new_seq, left_i=left_i, right_i=right_i, target=target,\n",
    "                                     negative=negative, decreasing=decreasing)\n",
    "            if len(new_df.index)>0:\n",
    "                new_seq = new_df.iloc[0]['seq']\n",
    "                df = new_df\n",
    "    return df\n",
    "\n",
    "\n",
    "# function to calculate the connections between nucleotides:\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "def connections_array (seq, target='expression', optimal_x_length=optimal_x_length,\n",
    "                     model_x_length=model_x_length, model=model):\n",
    "    # generate all point mutations:\n",
    "    all_mutants = all_possible_mutations(seq)\n",
    "    # add the original seq to the mutant list:\n",
    "    all_mutants.insert(0, seq)\n",
    "    # generate a list of saliency data.frames for each mutant:\n",
    "    df_list = [saliency_df(seq=seq, optimal_x_length=optimal_x_length, model_x_length=model_x_length,\n",
    "                       model=model, target=target) for seq in all_mutants]\n",
    "    # convert the data.frames into arrays by summing ATCG values:\n",
    "    all_saliencies = np.vstack([df.sum(axis=1) for df in df_list])\n",
    "    # calculate fold changes:\n",
    "    all_saliencies_fc = np.divide(all_saliencies[1:], all_saliencies[0])\n",
    "    # group the mutants by the position of mutations:\n",
    "    sub_arrays = np.array_split(all_saliencies_fc, len(all_saliencies_fc)/3)\n",
    "    # take medians:\n",
    "    medians_array = np.array([np.median(sub_array, axis=0) for sub_array in sub_arrays])\n",
    "    #\n",
    "    return medians_array\n",
    "\n",
    "\n",
    "# function to plot the connections:\n",
    "import seaborn as sns\n",
    "def plot_connections (array, size):\n",
    "    fig, ax = plt.subplots(figsize=(size, size))\n",
    "    ax = sns.heatmap(array, linewidth=0, center=1, cbar_kws={\"shrink\": .5}, vmin=0, vmax=2)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.invert_yaxis()\n",
    "    plt.ylabel('Mutated position', fontsize = 15, weight='bold')\n",
    "    plt.xlabel('Affected position', fontsize = 15, weight='bold')\n",
    "    #\n",
    "    ax.set_xticks(np.linspace(1.5, array.shape[1]-1.5, num=int(array.shape[1]/2)))\n",
    "    ax.set_yticks(np.linspace(1.5, array.shape[0]-1.5, num=int(array.shape[0]/2)))\n",
    "    #\n",
    "    ax.set_xticklabels([num for num in range(2, array.shape[1]+1, 2)])\n",
    "    ax.set_yticklabels([num for num in range(2, array.shape[0]+1, 2)])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07VnwnlFWhiB",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# k-mer context evolve:\n",
    "the_extreme_context_df = extreme_target_saliency_evolve(\n",
    "    seq='TTTTTTTTTTTTTTTTTTCTCCTCAATTTTTTTTTTTTTTTTTTT', # TTTTTTTTTTTTTTTTTTAAAAAAAATTTTTTTTTTTTTTTTTTT\n",
    "    left_i=19, right_i=26, target='export', negative=False, decreasing=True)\n",
    "the_extreme_context_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P9wjQjBnWhiC"
   },
   "outputs": [],
   "source": [
    "the_extreme_context_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N1Mydv6HWhiC",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "N45 = 'CACGCTCGTAATACGGTGAAAAAAAAAAACCCCTTCTCCCTTCCC'\n",
    "the_N45_saliency_df = saliency_df(seq=N45, target='expression')\n",
    "the_N45_saliency_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbRIPTUNWhiC"
   },
   "outputs": [],
   "source": [
    "plot_saliency(df=the_N45_saliency_df, negative=True, figsize=[8,2], xticks=True, yticks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MEM1i9daWhiD"
   },
   "outputs": [],
   "source": [
    "plot_saliency(df=the_N45_saliency_df, negative=False, figsize=[8,2], xticks=True, yticks=True,\n",
    "             ylim=[-0.04, 0.09])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D0PZXmDuWhiD"
   },
   "outputs": [],
   "source": [
    "con_arr = connections_array (seq=N45, target='export')\n",
    "con_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kHIh5ItEWhiD"
   },
   "outputs": [],
   "source": [
    "plot_connections(array=con_arr, size=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GiwA6PIVWhiD",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# quantify k-mer context effects:\n",
    "\n",
    "# function to generate random sequences containing a fixed k-mer in certain position:\n",
    "import random\n",
    "def kmer_random_contexts(num_seq=8, seq_len=45, fixed_kmer=\"TTTTTTTT\", fixed_kmer_start=19):\n",
    "    sequences = []\n",
    "    for _ in range(num_seq):\n",
    "        random_seq = ''.join(random.choice('ATCG') for _ in range(seq_len))\n",
    "        sequence = random_seq[:(fixed_kmer_start-1)] + fixed_kmer + random_seq[(fixed_kmer_start-1) + len(fixed_kmer):]\n",
    "        sequences.append(sequence)\n",
    "    return sequences\n",
    "\n",
    "kmer = 'TATGTTTT'\n",
    "phenotype = 'export'\n",
    "seq_len = 45\n",
    "kmer_position = 19\n",
    "num_seq = 256\n",
    "\n",
    "seqs = kmer_random_contexts(num_seq=num_seq, seq_len=seq_len, fixed_kmer=kmer, fixed_kmer_start=kmer_position)\n",
    "seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IiLK7k6DWhiE",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# negative control:\n",
    "kmer = 'Random'\n",
    "phenotype = 'export'\n",
    "seq_len = 45\n",
    "kmer_position = 19\n",
    "num_seq = 256\n",
    "\n",
    "# generate pure random seqs:\n",
    "import random\n",
    "def generate_random_sequence(length):\n",
    "    sequence = ''\n",
    "    nucleotides = ['A', 'T', 'C', 'G']\n",
    "    for _ in range(length):\n",
    "        sequence += random.choice(nucleotides)\n",
    "    return sequence\n",
    "\n",
    "seqs = []\n",
    "for _ in range(num_seq):\n",
    "    sequence = generate_random_sequence(seq_len)\n",
    "    seqs.append(sequence)\n",
    "\n",
    "seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E7ViqxlDWhiE"
   },
   "outputs": [],
   "source": [
    "# calculate k-mer position index:\n",
    "left_i = kmer_position\n",
    "right_i = left_i+len(kmer)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQZRf-OCWhiE"
   },
   "outputs": [],
   "source": [
    "# for NC:\n",
    "kmer_len = 8\n",
    "left_i = kmer_position\n",
    "right_i = left_i+kmer_len-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sUVvlnt6WhiE"
   },
   "outputs": [],
   "source": [
    "# create a new df:\n",
    "kmer_saliencies = pd.DataFrame(columns=['kmer', 'position', 'seq', 'phenotype', 'saliency'])\n",
    "# run saliency tests:\n",
    "for the_seq in seqs:\n",
    "    # generate saliency df:\n",
    "    the_seq_saliency_df = saliency_df(the_seq, target=phenotype)\n",
    "    # calculate k-mer saliency:\n",
    "    the_targeted_saliency = the_seq_saliency_df.loc[left_i:right_i].sum().sum()\n",
    "    new_data = pd.DataFrame({'kmer': [kmer],\n",
    "                             'position': [kmer_position],\n",
    "                             'seq': [the_seq],\n",
    "                             'phenotype': [phenotype],\n",
    "                             'saliency': [the_targeted_saliency]})\n",
    "    kmer_saliencies = pd.concat([kmer_saliencies, new_data], ignore_index=True)\n",
    "kmer_saliencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q98G3xtBWhiF"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.boxplot(data=kmer_saliencies, x=\"saliency\", y=\"kmer\", width=.5)\n",
    "plt.axvline(x=0, color='black', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OU-5nJkBWhiF"
   },
   "outputs": [],
   "source": [
    "# add new results to the df:\n",
    "all_kmer_saliencies = all_kmer_saliencies.append(kmer_saliencies, ignore_index=True)\n",
    "all_kmer_saliencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-fJWSePzWhiF"
   },
   "outputs": [],
   "source": [
    "# saliency medians:\n",
    "group_medians = all_kmer_saliencies.groupby('kmer')['saliency'].median()\n",
    "group_medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BUPHdTfQWhiF"
   },
   "outputs": [],
   "source": [
    "# normalize saliencies:\n",
    "all_kmer_saliencies['norm_saliency'] = all_kmer_saliencies.apply(\n",
    "    lambda row: row['saliency'] / group_medians[row['kmer']], axis=1\n",
    ")\n",
    "all_kmer_saliencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mByst95dWhiG"
   },
   "outputs": [],
   "source": [
    "all_kmer_saliencies[all_kmer_saliencies['kmer'] == 'TATTTATT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ENnW7mcWWhiG"
   },
   "outputs": [],
   "source": [
    "# draw boxplot as final result:\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "kmer_order = [\n",
    "    'AGGTAAGT', 'TTTTTTTT', 'AAAAAAAA', 'GGGGGGGG', 'TATGTTTT',\n",
    "    'TCGTCCCG', 'CTCCTCAA', 'ACGCCAGT', 'AACCACGT',\n",
    "    'TGAAGAAA', 'ACCCAGAA',\n",
    "    'TATTTATT', 'Random'\n",
    "]\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "sns.boxplot(data=all_kmer_saliencies, x=\"norm_saliency\", y=\"kmer\", order=kmer_order, width=.5)\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel('Fold changes in regulatory correlation', fontsize=13)\n",
    "ax.set_ylabel('Regulatory k-mers', fontsize=13)\n",
    "plt.xlim(-2, 4)\n",
    "plt.axvline(x=1, color='red', linestyle='--')\n",
    "plt.axvline(x=0, color='black', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EAZkPwFwWhiG"
   },
   "outputs": [],
   "source": [
    "# save:\n",
    "all_kmer_saliencies.to_csv('kmer_random_context_saliencies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r3q8xR_AWhiH"
   },
   "outputs": [],
   "source": [
    "# Function that performs one evolutionary step on the context of a k-mer:\n",
    "def evolve_target_saliency_once(seq, left_i=19, right_i=26, target='expression',\n",
    "                                 negative=True, decreasing=False):\n",
    "    # generate all mutants:\n",
    "    all_mutants = all_possible_mutations(seq)\n",
    "    # remove mutations on the k-mer:\n",
    "    del all_mutants[(left_i-1)*3 : right_i*3]\n",
    "    # add the original seq to the mutant list:\n",
    "    all_mutants.insert(0, seq)\n",
    "    # calculate target saliency of each mutant:\n",
    "    mut_saliencies = pd.DataFrame(columns=['seq', 'saliency'])\n",
    "    for the_seq in all_mutants:\n",
    "        the_N45_saliency_df = saliency_df(the_seq, target=target)\n",
    "        the_targeted_saliency = the_N45_saliency_df.loc[left_i:right_i].sum().sum()\n",
    "        if negative == True:\n",
    "            the_targeted_saliency = -the_targeted_saliency\n",
    "        mut_saliencies = mut_saliencies.append({'seq': the_seq, 'saliency': the_targeted_saliency},\n",
    "                                               ignore_index=True)\n",
    "    # only report improved ones:\n",
    "    if decreasing==True:\n",
    "        mut_saliencies = mut_saliencies.loc[mut_saliencies['saliency']<mut_saliencies['saliency'][0]]\n",
    "    else:\n",
    "        mut_saliencies = mut_saliencies.loc[mut_saliencies['saliency']>mut_saliencies['saliency'][0]]\n",
    "    # sort df by target:\n",
    "    mut_saliencies = mut_saliencies.sort_values(by='saliency', ascending=decreasing)\n",
    "    #\n",
    "    return mut_saliencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BsSEdv92WhiH"
   },
   "outputs": [],
   "source": [
    "# function to make a single-step evolution:\n",
    "def evolve_once (seq, target='expression', decreasing=False, exclude=['QWERT']):\n",
    "    # generate all mutants:\n",
    "    all_mutants = all_possible_mutations(seq)\n",
    "    # add the original seq to the mutant list:\n",
    "    all_mutants.insert(0, seq)\n",
    "    # check seq length:\n",
    "    seq_len = len(seq)\n",
    "    # predict the mutants:\n",
    "    # use different prediction strategy by seq length:\n",
    "    if seq_len == optimal_x_length:\n",
    "        x = prepare_x(all_mutants, model_x_length)\n",
    "        Model = load_model(model)\n",
    "        y_pred = Model.predict(x)\n",
    "    else:\n",
    "        y_pred = predict_big(big_seqs=all_mutants, k=optimal_x_length)\n",
    "    # convert array to dataframe:\n",
    "    pred_df = pd.DataFrame(y_pred, columns = ['nuc','cyt'])\n",
    "    # calculate values:\n",
    "    pred_df['nuc'] = 2**pred_df['nuc']\n",
    "    pred_df['cyt'] = 2**pred_df['cyt']\n",
    "    pred_df['expression'] = pred_df['cyt']*(16/17) + pred_df['nuc']*(1/17)\n",
    "    pred_df['export'] = pred_df['cyt']/pred_df['nuc']\n",
    "    # add seq to df:\n",
    "    pred_df['seq'] = all_mutants\n",
    "    # only report improved ones:\n",
    "    if decreasing==True:\n",
    "        pred_df = pred_df.loc[pred_df[target]<pred_df[target][0]]\n",
    "    else:\n",
    "        pred_df = pred_df.loc[pred_df[target]>pred_df[target][0]]\n",
    "    # exclude certain motifs:\n",
    "    rows_to_remove = pred_df[pred_df['seq'].str.contains('|'.join(exclude))]\n",
    "    pred_df = pred_df[~pred_df['seq'].isin(rows_to_remove['seq'])]\n",
    "    # sort df by target:\n",
    "    pred_df = pred_df.sort_values(by=target, ascending=decreasing)\n",
    "    #\n",
    "    return pred_df\n",
    "\n",
    "\n",
    "# Function to make extreme evolutions:\n",
    "def extreme_evolve(seq, target='expression', decreasing=False, exclude=['QWERT']):\n",
    "    # initiate the evolution:\n",
    "    df = evolve_once(seq, target=target, decreasing=decreasing, exclude=exclude)\n",
    "    # continue evolution if possible:\n",
    "    if len(df.index)>0:\n",
    "        new_seq = df.iloc[0]['seq']\n",
    "        new_df = df\n",
    "        while len(new_df.index)>0:\n",
    "            new_df = evolve_once(new_seq, target=target, decreasing=decreasing, exclude=exclude)\n",
    "            if len(new_df.index)>0:\n",
    "                new_seq = new_df.iloc[0]['seq']\n",
    "                df = new_df\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ejVitxsLWhiH",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate random sequences without certain elements:\n",
    "num_sequences = int(1e4)\n",
    "sequence_length = 360\n",
    "elements_to_replace = ['GT', 'GGGG', 'AAAA', 'TTTT']\n",
    "\n",
    "# function to generate a random seq:\n",
    "import random\n",
    "def generate_random_sequence(length):\n",
    "    bases = ['A', 'C', 'G', 'T']\n",
    "    return ''.join(random.choices(bases, k=length))\n",
    "\n",
    "# function to replace all elements in a seq to random:\n",
    "import re\n",
    "import random\n",
    "def replace_elements(sequence, elements):\n",
    "    pattern = r'|'.join([re.escape(e) for e in elements])\n",
    "    while True:\n",
    "        matches = re.findall(pattern, sequence)\n",
    "        if not matches:\n",
    "            break\n",
    "        for match in matches:\n",
    "            replacement = ''.join(random.choice('ACGT') for _ in range(len(match)))\n",
    "            sequence = sequence.replace(match, replacement, 1)\n",
    "    return sequence\n",
    "\n",
    "# perform generation:\n",
    "sequences = []\n",
    "for _ in range(num_sequences):\n",
    "    sequence = generate_random_sequence(sequence_length)\n",
    "    sequence = replace_elements(sequence, elements_to_replace)\n",
    "    sequences.append(sequence)\n",
    "\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5dxZ6LnWhiI"
   },
   "outputs": [],
   "source": [
    "# or:\n",
    "sequences = ['CATTCTCCACTTCTTGTTCCCCACTGACAGCCTCCCACCCCCATCTCTCCCTCCCCTGCCATTTTGGGTTTTGGGTCTTTGAACCCTTGCTTGCAATAGGTGTGCGTCAGAAGCACCCAGGACTTCCATTTGCTTTGTCCCGGGGCTCCACTGAACAAGTTGGCCTGCACTGGTGTTTTGTTGTGGGGAGGAGGATGGGGAGTAGGACATACCAGCTTAGATTTTAAGGTTTTTACTGTGAGGGATGTTTGGGAGATGTAAGAAATGTTCTTGCAGTTAAGGGTTAGTTTACAATCAGCCACATTCTAGGTAGGGGCCCACTTCACCGTACTAACCAGGGAAGCTGTCCCTCACTGTTGAATTTTCTCTAACTTCAAGGCCCATATCTGTGAAATGCTGGCATTTGCACCTACCTCACAGAGTGCATTGTGAGGGTTAATGAAATAATGTACATCTGGCCTTGAAACCACCTTTTATTACATGGGGTCTAGAACTTGACCCCCTTGAGGGTGCTTGTTCCCTCTCCCTGTTGGTCGGTGGGTTGGTAGTTTCTACAGTTGGGCAGCTGGTTAGGTAGAGGGAGTTGTCAAGTCTCTGCTGGCCCAGCCAAACCCTGTCTGACAACCTCTTGGTGAACCTTAGTACCTAAAAGGAAATCTCACCCCATCCCACACCCTGGAGGATTTCATCTCTTGTATATGATGATCTGGATCCACCAAGACTTGTTTTATGCTCAGGGTCAATTTCTTTTTTCTTTTTTTTTTTTTTTTTTCTTTTTCTTTGAGACTGGGTCTCGCTTTGTTGCCCAGGCTGGAGTGGAGTGGCGTGATCTTGGCTTACTGCAGCCTTTGCCTCCCCGGCTCGAGCAGTCCTGCCTCAGCCTCCGGAGTAGCTGGGACCACAGGTTCATGCCACCATGGCCAGCCAACTTTTGCATGTTTTGTAGAGATGGGGTCTCACAGTGTTGCCCAGGCTGGTCTCAAACTCCTGGGCTCAGGCGATCCACCTGTCTCAGCCTCCCAGAGTGCTGGGATTACAATTGTGAGCCACCACGTCCAGCTGGAAGGGTCAACATCTTTTACATTCTGCAAGCACATCTGCATTTTCACCCCACCCTTCCCCTCCTTCTCCCTTTTTATATCCCATTTTTATATCGATCTCTTATTTTACAATAAAACTTTGCTGCCA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7HScBE3kWhiI",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check elements:\n",
    "elements_to_check = elements_to_replace\n",
    "#\n",
    "def check_sequences(dna_sequences, elements):\n",
    "    containing_sequences = []\n",
    "    for index, sequence in enumerate(dna_sequences):\n",
    "        for element in elements:\n",
    "            if element in sequence:\n",
    "                containing_sequences.append(index)\n",
    "                break\n",
    "    return containing_sequences\n",
    "#\n",
    "check_sequences(sequences, elements_to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vj3IHeoyWhiI"
   },
   "outputs": [],
   "source": [
    "# define model .hdf5 file:\n",
    "model = '/content/L5-220528_em5-LSTM64x32x0.5-64x0.5-rep4.hdf5'\n",
    "# em5>LSTM64x32*0.5>64*0.5-rep4\n",
    "# CNN8*512>GAP>128\n",
    "# CNN8*256>GAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LrYJHGP1WhiI"
   },
   "outputs": [],
   "source": [
    "# apply prediction:\n",
    "y_pred = predict_big(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c6BQW9p7WhiJ"
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7c6boUNwWhiJ"
   },
   "outputs": [],
   "source": [
    "# convert result:\n",
    "pred_df = pd.DataFrame(y_pred, columns = ['nuc','cyt'])\n",
    "# calculate values:\n",
    "pred_df['nuc'] = 2**pred_df['nuc']\n",
    "pred_df['cyt'] = 2**pred_df['cyt']\n",
    "pred_df['expression'] = pred_df['cyt']*(16/17) + pred_df['nuc']*(1/17)\n",
    "pred_df['export'] = pred_df['cyt']/pred_df['nuc']\n",
    "pred_df['seq'] = sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cQ6affqmWhiK"
   },
   "outputs": [],
   "source": [
    "# sort:\n",
    "pred_df = pred_df.sort_values(by='export', ascending=True)\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0YWYGILWhiK"
   },
   "outputs": [],
   "source": [
    "# save:\n",
    "pred_df.to_csv('N360_nonGT,GGGG,AAAA,TTTT_1e4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X_o43ftlWhiL"
   },
   "outputs": [],
   "source": [
    "# load:\n",
    "import pandas as pd\n",
    "pred_df = pd.read_csv('N360_nonGT_1e3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13cPhlcbWhiL"
   },
   "outputs": [],
   "source": [
    "pred_df.iloc[0]['seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1qV3O-uAWhiL"
   },
   "outputs": [],
   "source": [
    "# 3'UTR saliency test:\n",
    "# define 3'UTR sequence (ATCG only):\n",
    "seq = 'AGCTCTTGACATGAAAGAAAGCCTTTCTCTTCATGCAACCATGGACATCTTTCCTATGTTTTGGAAGTTTCTAAAAGACTTTTGGGTTA'\n",
    "len(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ySu3wYqXWhiL"
   },
   "outputs": [],
   "source": [
    "# define target:\n",
    "target = 'expression'  # 'expression'/'export'\n",
    "negative = False  # True/False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F4wIVi7eWhiM",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nucleotide saliency test:\n",
    "sal_df = saliency_df(seq=seq, target=target)\n",
    "sal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_saliency(df=sal_df, negative=False, figsize=[8,2], xticks=True, yticks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_saliency(df=sal_df, negative=False, figsize=[8,2], xticks=True, yticks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3nPPAxB9WhiM"
   },
   "outputs": [],
   "source": [
    "plot_saliency(sal_df, negative=negative, start=0, end=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q__Cp-iJWhiM"
   },
   "outputs": [],
   "source": [
    "# run extreme evolution:\n",
    "exclude_elements = elements_to_replace\n",
    "evo_df = extreme_evolve(seq, target='export', decreasing=True, exclude=exclude_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2KGpoJfUWhiN"
   },
   "outputs": [],
   "source": [
    "evo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SF3WbdcTWhiN"
   },
   "outputs": [],
   "source": [
    "evo_df.iloc[0]['seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9DmWWeaWhiN"
   },
   "outputs": [],
   "source": [
    "# nucleotide interactions:\n",
    "arr = connections_array(seq, target='export') # 'expression'/'export'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MpKA0PCsWhiN"
   },
   "outputs": [],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gp0z6_D1WhiO"
   },
   "outputs": [],
   "source": [
    "plot_connections(arr, size=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4fvlg6PdWhiO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
