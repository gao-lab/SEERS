{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable tensorflow warnings:\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU usage:\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick GPU:\n",
    "GPU_id = '2'\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=GPU_id\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PAuB1_bp1x1S",
    "outputId": "b837882f-4c46-4002-80c4-f71197249a3a"
   },
   "outputs": [],
   "source": [
    "# Limit GPU memory growth:\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "# Check gpu:\n",
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hkMTZLFS-8sE",
    "outputId": "95ca8539-4134-4cd8-e345-4e41636ecd9e"
   },
   "outputs": [],
   "source": [
    "# Check number of CPU cores:\n",
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inputs:\n",
    "train_tsv = 'L5_log2expression_train_220528.tsv' # training data\n",
    "val_tsv = 'L5_log2expression_val_220528.tsv' # validation data\n",
    "test_tsv = 'L5_log2expression_test_220528.tsv' # test data\n",
    "\n",
    "# Load data:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "train_df = pd.read_table(train_tsv)\n",
    "val_df = pd.read_table(val_tsv)\n",
    "test_df = pd.read_table(test_tsv)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert letters to indexes:\n",
    "vocab = ['pad','N','A','T','C','G'] # 'pad' has to be first (0)\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "def vectorize_string(string):\n",
    "    vectorized_output = [char2idx[char] for char in string]\n",
    "    return vectorized_output\n",
    "\n",
    "train_df['Nni'] = train_df['Nn'].apply(vectorize_string)\n",
    "val_df['Nni'] = val_df['Nn'].apply(vectorize_string)\n",
    "test_df['Nni'] = test_df['Nn'].apply(vectorize_string)\n",
    "\n",
    "# Specify x:\n",
    "train_x = train_df.Nni\n",
    "val_x = val_df.Nni\n",
    "test_x = test_df.Nni\n",
    "\n",
    "# Array x, empty spaces will be assigned as 0 ('pad'):\n",
    "N = len(max(train_df['Nni'], key=len))\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "train_x = pad_sequences(train_x, maxlen=N, padding='post')\n",
    "val_x = pad_sequences(val_x, maxlen=N, padding='post')\n",
    "test_x = pad_sequences(test_x, maxlen=N, padding='post')\n",
    "\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare y:\n",
    "train_y = train_df[['nuc.log2expression', 'cyt.log2expression']].to_numpy()\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y = val_df[['nuc.log2expression', 'cyt.log2expression']].to_numpy()\n",
    "val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = test_df[['nuc.log2expression', 'cyt.log2expression']].to_numpy()\n",
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Snth6iqzD1c",
    "outputId": "f6bed892-397c-40f6-a722-db3e4ac070c6"
   },
   "outputs": [],
   "source": [
    "# LSTM:\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "import keras\n",
    "\n",
    "# Initiate the model:\n",
    "Model = Sequential()\n",
    "# Input layer:\n",
    "embed_dim = 5\n",
    "Model.add(Embedding(input_length=train_x.shape[1], input_dim=len(vocab), output_dim=embed_dim))\n",
    "# LSTM layer:\n",
    "Model.add(LSTM(64, return_sequences=True))\n",
    "Model.add(LSTM(32, return_sequences=True))\n",
    "Model.add(Dropout(0.5))\n",
    "# Dense layer:\n",
    "Model.add(Flatten())\n",
    "Model.add(Dense(64, activation='relu'))\n",
    "Model.add(Dropout(0.5))\n",
    "# Output layer:\n",
    "Model.add(Dense(2, activation='linear'))\n",
    "\n",
    "\n",
    "# Define optimizer:\n",
    "learning_rate = 0.5**11\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "Model.compile(loss='mae', optimizer=optimizer)\n",
    "\n",
    "# Name the model:\n",
    "output_model = 'models/L5-220528_em5>LSTM64x32*0.5>64*0.5-rep9.hdf5'\n",
    "\n",
    "# Show architechture:\n",
    "Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear CNN:\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.layers import MaxPooling1D\n",
    "import keras\n",
    "\n",
    "# Initiate the model:\n",
    "Model = Sequential()\n",
    "# Input layer:\n",
    "embed_dim = 4\n",
    "Model.add(Embedding(input_dim=len(vocab), output_dim=embed_dim, input_length=train_x.shape[1]))\n",
    "# 8-mers:\n",
    "Model.add(Conv1D(256, kernel_size=8, strides=1, activation='relu'))\n",
    "# feature counts:\n",
    "Model.add(GlobalAveragePooling1D())\n",
    "# Output layer:\n",
    "Model.add(Dense(2, activation='linear'))\n",
    "\n",
    "\n",
    "# Define optimizer:\n",
    "learning_rate = 0.5**4\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "Model.compile(loss='mae', optimizer=optimizer)\n",
    "\n",
    "# Name the model:\n",
    "output_model = 'models/L5-220528_CNN8*256>GAP-rep4.hdf5'\n",
    "\n",
    "# Show architechture:\n",
    "Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU usage:\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "55xpDdwOzD1d",
    "outputId": "531f08a3-5fdf-4496-9505-96f0e6678f5e",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set training:\n",
    "batch_size = 65536\n",
    "add_epoch = 4096\n",
    "# Set recording:\n",
    "Best_model_path = output_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(Best_model_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "# Perform training:\n",
    "history = Model.fit(train_x, train_y, validation_data=(val_x, val_y), shuffle=True, \n",
    "                    callbacks=callbacks_list, batch_size=batch_size, epochs=add_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "SlKcMREiGrqs",
    "outputId": "33c2a5ba-9959-4e63-97a4-cf4a45a0ef8a"
   },
   "outputs": [],
   "source": [
    "# Plot training history:\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Training history',fontsize=15)\n",
    "plt.ylabel('Loss', fontsize=15)\n",
    "plt.xlabel('Epoch', fontsize=15)\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.axhline(y=min(history.history['val_loss']), color='tab:orange', linestyle='--', linewidth=0.5)\n",
    "plt.axvline(x=np.argmin(history.history['val_loss']), color='tab:orange', linestyle='--', linewidth=0.5)\n",
    "plt.axhline(y=min(history.history['loss']), color='tab:blue', linestyle='--', linewidth=0.5)\n",
    "plt.axvline(x=np.argmin(history.history['loss']), color='tab:blue', linestyle='--', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train mae:\n",
    "from keras.models import load_model\n",
    "BestModel = load_model(Best_model_path)\n",
    "pred_y = BestModel.predict(train_x)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "train_mae = mean_absolute_error(train_y, pred_y)\n",
    "train_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation mae:\n",
    "pred_y = BestModel.predict(val_x)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "val_mae = mean_absolute_error(val_y, pred_y)\n",
    "val_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation mse:\n",
    "from sklearn.metrics import mean_squared_error\n",
    "val_mse = mean_squared_error(val_y, pred_y)\n",
    "val_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "VGj8Yzq-zD1f",
    "outputId": "76a9c9ca-1149-4e47-a523-0bb7795fd7b6"
   },
   "outputs": [],
   "source": [
    "# predict test data:\n",
    "pred_y = BestModel.predict(test_x)\n",
    "# Plot nuc.log2expression comparison:\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 8))\n",
    "a = plt.axes(aspect='equal')\n",
    "plt.scatter((test_y[:,0]), (pred_y[:,0]), s=0.7, c='black')\n",
    "plt.xlabel('Measured', fontsize=17)\n",
    "plt.ylabel('Predicted', fontsize=17)\n",
    "test_y_max = max((test_y[:,0]))\n",
    "test_y_min = min((test_y[:,0]))\n",
    "pred_y_max = float(max((pred_y[:,0])))\n",
    "pred_y_min = float(min((pred_y[:,0])))\n",
    "the_max = max(test_y_max, pred_y_max)\n",
    "the_min = min(test_y_min, pred_y_min)\n",
    "lims = [the_min, the_max]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "_ = plt.plot(lims, lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2:\n",
    "from sklearn import metrics\n",
    "metrics.r2_score(test_y[:,0], pred_y[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.r2_score(pred_y[:,0], test_y[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cyt.log2expression comparison:\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 8))\n",
    "a = plt.axes(aspect='equal')\n",
    "plt.scatter((test_y[:,1]), (pred_y[:,1]), s=0.7, c='black')\n",
    "plt.xlabel('Measured', fontsize=17)\n",
    "plt.ylabel('Predicted', fontsize=17)\n",
    "test_y_max = max((test_y[:,1]))\n",
    "test_y_min = min((test_y[:,1]))\n",
    "pred_y_max = float(max((pred_y[:,1])))\n",
    "pred_y_min = float(min((pred_y[:,1])))\n",
    "the_max = max(test_y_max, pred_y_max)\n",
    "the_min = min(test_y_min, pred_y_min)\n",
    "lims = [the_min, the_max]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "_ = plt.plot(lims, lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2:\n",
    "from sklearn import metrics\n",
    "metrics.r2_score(test_y[:,1], pred_y[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.r2_score(pred_y[:,1], test_y[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SEERR_ANN_ATCGN_input.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
