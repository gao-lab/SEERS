{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "voq_EIyaOPzX",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure TensorFlow is below 2.16! Otherwise the model won't be able to load.\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkkgAZHvWhh8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GPU info:\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mHxe2YXWhh9"
   },
   "outputs": [],
   "source": [
    "# Assign GPU to use:\n",
    "GPU_id = '7'\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = GPU_id\n",
    "\n",
    "# check GPU:\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "print(f\"Num GPUs Available: {len(gpu_devices)}\")\n",
    "\n",
    "if gpu_devices:\n",
    "    print(\"GPU working\")\n",
    "    for device in gpu_devices:\n",
    "        print(f\"Device name: {device.name}\")\n",
    "        print(f\"Device type: {device.device_type}\")\n",
    "else:\n",
    "    print(\"GPU not working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RAQNScryWhh_"
   },
   "outputs": [],
   "source": [
    "# Function to generate a list of all possible mutations for a seq:\n",
    "def all_possible_mutations(dna_seq):\n",
    "    mutated_seqs = []\n",
    "    for i in range(len(dna_seq)):\n",
    "        for nucleotide in [\"A\", \"T\", \"C\", \"G\"]:\n",
    "            if nucleotide != dna_seq[i]:\n",
    "                mutated_seq = dna_seq[:i] + nucleotide + dna_seq[i+1:]\n",
    "                mutated_seqs.append(mutated_seq)\n",
    "    #\n",
    "    return mutated_seqs\n",
    "\n",
    "# function to plot nucleotide saliencies:\n",
    "import logomaker\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_saliency(df, negative=False,\n",
    "                  start=None, end=None, figsize=[8,2],\n",
    "                  xticks=False, yticks=False,\n",
    "                  spines=False, ylim=None):\n",
    "    # make Figure and Axes objects:\n",
    "    fig, ax = plt.subplots(1,1,figsize=figsize)\n",
    "    # limit x range, if defined:\n",
    "    if start is not None and end is not None:\n",
    "        df = df[start : end+1]\n",
    "    elif start is not None:\n",
    "        df = df[start : ]\n",
    "    elif end is not None:\n",
    "        df = df[ : end+1]\n",
    "    # flip saliencies if defined:\n",
    "    if negative == True:\n",
    "        df = -df\n",
    "    #\n",
    "    logo = logomaker.Logo(df, ax=ax)\n",
    "    #\n",
    "    if ylim is not None:\n",
    "        logo.ax.set_ylim(ylim)\n",
    "    #\n",
    "    if spines==False:\n",
    "        logo.style_spines(visible=False)\n",
    "    #\n",
    "    if xticks==False:\n",
    "        ax.set_xticks([])\n",
    "    #\n",
    "    if yticks==False:\n",
    "        ax.set_yticks([])\n",
    "    #\n",
    "    return logo.fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1BIznd3tWhiA"
   },
   "outputs": [],
   "source": [
    "# Define the model:\n",
    "model = '/rd4/users/liangn/mywork/L5-220528_em5-LSTM64x32x0.5-64x0.5-rep4.hdf5'\n",
    "model_x_length = 46\n",
    "optimal_x_length = 45\n",
    "\n",
    "\n",
    "# Function to convert a DNA sequence to vector:\n",
    "vocab = ['pad','N','A','T','C','G']\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "def vectorize_dna_seq(dna_seq):\n",
    "    vectorized_dna_seq = [char2idx[char] for char in dna_seq]\n",
    "    return vectorized_dna_seq\n",
    "\n",
    "\n",
    "# Function to convert a list of DNA into x array for ANN inputs:\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "def prepare_x(dna_list, x_lenth):\n",
    "    x = list(map(vectorize_dna_seq, dna_list))\n",
    "    x = pad_sequences(x, maxlen=x_lenth, padding='post')\n",
    "    #\n",
    "    return x\n",
    "\n",
    "\n",
    "# function to split a string into k-mers:\n",
    "def kmerize(string, k):\n",
    "    return [string[i:i+k] for i in range(len(string)-k+1)]\n",
    "\n",
    "\n",
    "# function to predict big seq with sliding windows:\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "def predict_big(big_seqs, k=optimal_x_length, model_x_length=model_x_length, model=model):\n",
    "    # form data.frame:\n",
    "    # if big_seqs only had one, convert to a list as well:\n",
    "    if isinstance(big_seqs, str):\n",
    "        big_seqs = [big_seqs]\n",
    "    seq_df = pd.DataFrame({'seq': big_seqs})\n",
    "    # split each seq into k-mers, mark indexes:\n",
    "    seq_df = seq_df['seq'].apply(lambda x: kmerize(x, k))\n",
    "    seq_df = seq_df.apply(pd.Series)\n",
    "    seq_df = seq_df.stack().reset_index(level=1, drop=True).to_frame('seq')\n",
    "    # prepare x for predictions:\n",
    "    x = seq_df['seq'].apply(vectorize_dna_seq)\n",
    "    x = pad_sequences(x, maxlen=model_x_length, padding='post')\n",
    "    # predict:\n",
    "    Model = load_model(model)\n",
    "    y_pred = Model.predict(x)\n",
    "    # take group means of the same indexes:\n",
    "    unique_index = np.unique(seq_df.index)\n",
    "    y_pred_mean = np.zeros((len(unique_index), y_pred.shape[1]))\n",
    "    for i in range(len(unique_index)):\n",
    "        y_pred_mean[i] = np.mean(y_pred[seq_df.index == unique_index[i]], axis=0)\n",
    "    #\n",
    "    return y_pred_mean\n",
    "\n",
    "\n",
    "# function to get a df of the regulatory relevance of each nucleotide of a seq:\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "def saliency_df(seq, optimal_x_length=optimal_x_length, model_x_length=model_x_length, model=model,\n",
    "                target='expression'):\n",
    "    # generate all point mutations:\n",
    "    all_mutants = all_possible_mutations(seq)\n",
    "    # add the original seq to the mutant list:\n",
    "    all_mutants.insert(0, seq)\n",
    "    # check seq length:\n",
    "    seq_len = len(seq)\n",
    "    # predict the mutants:\n",
    "    # use different prediction strategy by seq length:\n",
    "    if seq_len == optimal_x_length:\n",
    "        x = prepare_x(all_mutants, model_x_length)\n",
    "        Model = load_model(model)\n",
    "        y_pred = Model.predict(x)\n",
    "    else:\n",
    "        y_pred = predict_big(big_seqs=all_mutants, k=optimal_x_length, model_x_length=model_x_length,\n",
    "                             model=model)\n",
    "    # convert array to dataframe:\n",
    "    pred_df = pd.DataFrame(y_pred, columns = ['nuc','cyt'])\n",
    "    # calculate values:\n",
    "    pred_df['nuc'] = 2**pred_df['nuc']\n",
    "    pred_df['cyt'] = 2**pred_df['cyt']\n",
    "    pred_df['expression'] = pred_df['cyt']*(16/17) + pred_df['nuc']*(1/17)\n",
    "    pred_df['export'] = pred_df['cyt']/pred_df['nuc']\n",
    "    # calculate delta:\n",
    "    values = pred_df[target].values\n",
    "    deltas = values[0] - values[1:]\n",
    "    # median deltas of each original nucleotide/position:\n",
    "    delta_medians = []\n",
    "    for i in range(3, len(deltas)+1, 3):\n",
    "      median = np.median(deltas[i-3:i])\n",
    "      delta_medians.append(median)\n",
    "    # form the final data.frame suitable for logomaker:\n",
    "    seq_list = list(seq)\n",
    "    df = pd.DataFrame(columns=['A', 'C', 'G', 'T'])\n",
    "    for i, letter in enumerate(seq_list):\n",
    "      df.at[i, letter] = delta_medians[i]\n",
    "    df = df.fillna(0)\n",
    "    df = df.astype('float64')\n",
    "    # change row index to 1,2,3...:\n",
    "    df.index = range(1, len(df) + 1)\n",
    "    #\n",
    "    return df\n",
    "\n",
    "\n",
    "# function to calculate the connections between nucleotides:\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "def connections_array (seq, target='expression', optimal_x_length=optimal_x_length,\n",
    "                     model_x_length=model_x_length, model=model):\n",
    "    # generate all point mutations:\n",
    "    all_mutants = all_possible_mutations(seq)\n",
    "    # add the original seq to the mutant list:\n",
    "    all_mutants.insert(0, seq)\n",
    "    # generate a list of saliency data.frames for each mutant:\n",
    "    df_list = [saliency_df(seq=seq, optimal_x_length=optimal_x_length, model_x_length=model_x_length,\n",
    "                       model=model, target=target) for seq in all_mutants]\n",
    "    # convert the data.frames into arrays by summing ATCG values:\n",
    "    all_saliencies = np.vstack([df.sum(axis=1) for df in df_list])\n",
    "    # calculate fold changes:\n",
    "    all_saliencies_fc = np.divide(all_saliencies[1:], all_saliencies[0])\n",
    "    # group the mutants by the position of mutations:\n",
    "    sub_arrays = np.array_split(all_saliencies_fc, len(all_saliencies_fc)/3)\n",
    "    # take medians:\n",
    "    medians_array = np.array([np.median(sub_array, axis=0) for sub_array in sub_arrays])\n",
    "    #\n",
    "    return medians_array\n",
    "\n",
    "\n",
    "# function to plot the connections:\n",
    "import seaborn as sns\n",
    "def plot_connections (array, size):\n",
    "    fig, ax = plt.subplots(figsize=(size, size))\n",
    "    ax = sns.heatmap(array, linewidth=0, center=1, cbar_kws={\"shrink\": .5}, vmin=0, vmax=2)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.invert_yaxis()\n",
    "    plt.ylabel('Mutated position', fontsize = 15, weight='bold')\n",
    "    plt.xlabel('Affected position', fontsize = 15, weight='bold')\n",
    "    #\n",
    "    ax.set_xticks(np.linspace(1.5, array.shape[1]-1.5, num=int(array.shape[1]/2)))\n",
    "    ax.set_yticks(np.linspace(1.5, array.shape[0]-1.5, num=int(array.shape[0]/2)))\n",
    "    #\n",
    "    ax.set_xticklabels([num for num in range(2, array.shape[1]+1, 2)])\n",
    "    ax.set_yticklabels([num for num in range(2, array.shape[0]+1, 2)])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N1Mydv6HWhiC",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "N45 = 'CGATCATCTTCATCATCGTCATCATCCGTCTTCCATCCATCCAGT'\n",
    "the_N45_saliency_df = saliency_df(seq=N45, target='export')\n",
    "the_N45_saliency_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbRIPTUNWhiC"
   },
   "outputs": [],
   "source": [
    "plot_saliency(df=the_N45_saliency_df, negative=False, figsize=[8,2], xticks=True, yticks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D0PZXmDuWhiD",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "con_arr = connections_array (seq=N45, target='export')\n",
    "con_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "con_df = pd.DataFrame(con_arr)\n",
    "con_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save:\n",
    "con_df.to_csv('fig4bbot4.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kHIh5ItEWhiD"
   },
   "outputs": [],
   "source": [
    "plot_connections(array=con_arr, size=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
